# Lemmatisation using Deep Learning

Author: Tsolak Ghukasyan

## Introduction

Lemmatization tools often require linguistic expertise and are usually based on rules and lookup tables. To break the linguistic barrier, this project aims to utilise annotated text datasets and word embeddings and develop a universal model for lemmatization. Since there are lemma-annotated UD treebanks and fastText embeddings publicly available for over 60 different languages, the proposed project can be used to train lemmatization models for dozens of languages.

## Roadmap

_Milestone 1_
supervised models for 2 UD languages with evaluation and analysis.

_Milestone 2_
* semi-supervised or unsupervised models for at least 5 UD languages with evaluation.
* registered implementation at PyPi.

## Resources

For training and evaluation:

UD treebanks: http://universaldependencies.org/
Word embeddings: https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md 

## Related Work

https://pdfs.semanticscholar.org/12c6/1ee4f804d4007fc12cfd0d13ba260c051e48.pdf
